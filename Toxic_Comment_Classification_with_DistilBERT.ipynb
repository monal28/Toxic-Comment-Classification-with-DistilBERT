{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Cw3zTrngoBl"
   },
   "source": [
    "# **Section 1 - Setting up the environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "424ba21b"
   },
   "source": [
    "## Mount Google Drive & Set Working Directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN0ZCmMtiU07"
   },
   "source": [
    "We start by mounting Google Drive to access our dataset and navigating to the appropriate folder for training assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhYP4aO87uH3"
   },
   "outputs": [],
   "source": [
    "# After cloning the GitHub repo into Colab\n",
    "%cd /content\n",
    "\n",
    "!git clone https://github.com/monal28/Toxic-Comment-Classification-with-DistilBERT.git\n",
    "\n",
    "%cd Toxic-Comment-Classification-with-DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kc_PkSlHBJgt",
    "outputId": "2b64848e-868e-461c-b68b-af8455c433aa"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#import os\n",
    "\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#folder_path = '/content/drive/MyDrive/NLP3'\n",
    "#os.chdir(folder_path)\n",
    "\n",
    "# List files in the working directory\n",
    "#!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5a4e031"
   },
   "source": [
    "## Check GPU Availability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Hq29Sg0iYC1"
   },
   "source": [
    "We detect the number of available GPUs to adjust our batch size accordingly and accelerate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_oEXq4pJiIz",
    "outputId": "340f3051-7d40-4d06-a18e-0e0a3f3307e0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Detect number of GPUs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"Number of GPUs:\", n_gpu)\n",
    "\n",
    "# Batch size and training config\n",
    "BASE_BATCH_SIZE = 16\n",
    "BATCH_SIZE = BASE_BATCH_SIZE * max(1, n_gpu)\n",
    "EPOCHS = 3\n",
    "MAX_LEN = 192\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt_VEvicfN5T",
    "outputId": "75ffee91-21f9-42f1-ed76-f8d51f6de0b1"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "638af18e"
   },
   "source": [
    "## Import Essential Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY-4uen0iQ7A"
   },
   "source": [
    "We import essential libraries for:\n",
    "- Data handling (`pandas`, `numpy`)\n",
    "- Model training (`torch`, `transformers`)\n",
    "- Evaluation (`sklearn`)\n",
    "- Visualization (`matplotlib`, `seaborn`, `plotly`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcKKQuO_xskt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Data & Progress\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Transformers and Tokenizers\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lyuNyK5gwAc"
   },
   "source": [
    "# **Section 2 - Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "904d8ee9"
   },
   "source": [
    "## Load Dataset\n",
    "We load the multilingual toxic comment dataset from Jigsaw, including training, validation, and test sets. A smaller subset is used for faster experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7d8Jg1yBLzy"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('jigsaw-toxic-comment-train.csv', nrows=10000)\n",
    "valid = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv', nrows=5000)\n",
    "test_labels = pd.read_csv(\"test_labels.csv\", nrows=5000)\n",
    "#sub = pd.read_csv('sample_submission.csv', nrows=5000)\n",
    "\n",
    "#sub_en = pd.read_csv('sample_submission.csv', nrows=5000)\n",
    "test_en = pd.read_csv('jigsaw-toxic-comment-train.csv')\n",
    "test_en = test_en.tail(5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5f7339a"
   },
   "source": [
    "## Data Preprocessing\n",
    "- Tokenize text using the `distilbert-base-multilingual-cased` tokenizer\n",
    "- Pad and truncate to 192 tokens\n",
    "- Format inputs with attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "5878477b88764d0ab1ee80fd21a39760",
      "cf2e53d8719e4c04a9d9305a6cadc89a",
      "ad32d28fcb474a5f8ffe2a9d487acc94",
      "9195a4622fad4a4991a4f70d56c225d0",
      "321cfb29174b43218c7bbd33aed8b9f1",
      "3f63424043094b7dbed28db2147185bb",
      "1a3a415443d1421bbb6c9454c0952849",
      "5743b382a7a9450e80112fa4cf6eac99",
      "19081cc4292c4177990491c6ee7adb30",
      "ac474f71f9c14872a9e726f2fe41c9e4",
      "af3c2819efc54b40b758cf4ae6c58276",
      "f7c9547d3f4e42adabaf7fc4a7327687",
      "c5bcf3d103ca4917a4b58b04cf5e9d71",
      "b3b9e71edb1044159c65d62e214c7f0e",
      "4f06e5e957364f1ca983fc535db83aae",
      "d5f160c5b1354b639a4b255af97a59d5",
      "31162f1133ee4cebb37e872b314ea45f",
      "379d2538225f4d739df2b02c1555c050",
      "7aa3cf22eef941a9b9b766cc86dc934d",
      "1458317d1b024898bb4abaf617597693",
      "dbda581ccaad4ffcaf2da2e0227e99b2",
      "e4f13b6564384fe48e478075201b5e7b",
      "ea5f2c03dc6e4260bb099887cfc8cf94",
      "9c811fc3dc8847229ab5a336159aec61",
      "80aef52ac73048189835ae8389281eab",
      "cf7939f1b2d84a0e8ab297a59ef958f3",
      "beb7145ccea94872b80ec66bb9dfbd1a",
      "be37ae31a9204e13a89df9cd96f7290b",
      "23003f74f207462e8da5b6e88aea228e",
      "26463436a9824ca2b4f5e2a3aeacdf10",
      "39638933ce4f480f814884e9ecef573a",
      "8370372ad6754a03aa717a91ada960cb",
      "df4cc47a301c49b88c585e879ccd41e4",
      "c40b9f47fdd1400fa923f6c517124b3a",
      "742a941da9ab402eab53b53a3ded9429",
      "56e1889785b443e399087199fab6e4ee",
      "cbc2b3112c07455c873ffc5a0787ceb7",
      "4b8cbc4d8d214ba38638b4debc34323a",
      "e2da152027574e4a97930f14c2627c94",
      "48887d1805d34b39a1633bb02d6bf56d",
      "cea8c0ecf618462d93d76871b59eaff5",
      "071f8a39564d45b1bcccd98794131191",
      "663cb15f14874b54baf98328ad71fdfb",
      "13b11bebe3a94d8ca348e1c264dd0202"
     ]
    },
    "id": "kqy04Z46GNKg",
    "outputId": "6129efa4-fa84-442a-8203-6282ef550257"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6DTUdPoGgTa"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def encode_dataset(texts, tokenizer, max_len=512, chunk_size=256):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), chunk_size), desc=\"Tokenizing\"):\n",
    "        text_chunk = texts[i:i + chunk_size].tolist()\n",
    "        encodings = tokenizer(\n",
    "            text_chunk,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encodings['input_ids'])\n",
    "        attention_masks.append(encodings['attention_mask'])\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    all_input_ids = torch.cat(input_ids)\n",
    "    all_attention_masks = torch.cat(attention_masks)\n",
    "    return all_input_ids, all_attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuVKLFUAHu6F",
    "outputId": "27b915a1-ca6a-401b-ddd9-763ce6201971"
   },
   "outputs": [],
   "source": [
    "x_train_input_ids, x_train_attention_mask = encode_dataset(train.comment_text.astype(str), tokenizer, max_len=MAX_LEN)\n",
    "x_valid_input_ids, x_valid_attention_mask = encode_dataset(valid.comment_text.astype(str), tokenizer, max_len=MAX_LEN)\n",
    "x_test_input_ids, x_test_attention_mask = encode_dataset(test.content.astype(str), tokenizer, max_len=MAX_LEN)\n",
    "x_test_en_input_ids, x_test_en_attention_mask = encode_dataset(test_en.comment_text.astype(str), tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "y_train = torch.tensor(train.toxic.values, dtype=torch.float)\n",
    "y_valid = torch.tensor(valid.toxic.values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkU7sY8-gfW6"
   },
   "source": [
    "## Define PyTorch Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ke_xuGigKpxY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx]\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C6Ua6nQgMZq"
   },
   "source": [
    "##  Prepare Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzX9brVxLf34"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = ToxicDataset(x_train_input_ids, x_train_attention_mask, y_train)\n",
    "valid_dataset = ToxicDataset(x_valid_input_ids, x_valid_attention_mask, y_valid)\n",
    "test_dataset = ToxicDataset(x_test_input_ids, x_test_attention_mask)\n",
    "test_dataset_en = ToxicDataset(x_test_en_input_ids, x_test_en_attention_mask)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "test_loader_en = DataLoader(test_dataset_en, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48Cq4Jf4hDrP"
   },
   "source": [
    "# **Section 3 - Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03e290c0"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhkl4LMSDwh7"
   },
   "source": [
    "We use a DistilBERT model architecture with a custom binary classification head:\n",
    "\n",
    "- Pretrained base: `distilbert-base-multilingual-cased`\n",
    "\n",
    "- Final layer: Fully connected (Linear) layer mapping to a single output for binary classification (toxic vs non-toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d6f0e349f55444da854e7ff967143559",
      "8fc6a04b5cb142b5b06e341292946303",
      "09adeca304924970a3e75cdbda18c303",
      "cd1c45573c554571ae1d1873002f648f",
      "37cdc1eb0645497793ebce24e4b05dd1",
      "6dad53b297e3401ca26877e5c740495c",
      "bc512bb2dfa048c8a54b7b13b658148e",
      "e8c1ac55042e4592ad36995d5b5aa7f8",
      "c959e06cfa2e4d8da308bed78b66f2b1",
      "519166bf063b41a8aea8d3fa965e49e0",
      "abad889e76e04535912fc5f18f854b6e"
     ]
    },
    "id": "ivw-4EmGMzUe",
    "outputId": "6790efdc-10dd-4bff-e977-2206d00b85d1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class ToxicClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"distilbert-base-multilingual-cased\"):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :]  # use [CLS] token\n",
    "        logits = self.classifier(cls_token)\n",
    "        return logits\n",
    "\n",
    "model = ToxicClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbJC5F81hTjL"
   },
   "source": [
    "## Training Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDafhKCrD2YQ"
   },
   "source": [
    "We configure the training loop using:\n",
    "\n",
    "Optimizer: Adam\n",
    "\n",
    "Loss function: Weighted `BCEWithLogitsLoss` to account for class imbalance\n",
    "\n",
    "Metrics: Accuracy and ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta0kBYxnM0VF"
   },
   "outputs": [],
   "source": [
    "# Count positive (toxic) and negative (non-toxic) samples\n",
    "num_pos = y_train.sum()\n",
    "num_neg = len(y_train) - num_pos\n",
    "\n",
    "# Compute weight for positive class (toxic)\n",
    "pos_weight_value = num_neg / num_pos\n",
    "\n",
    "# Wrap it in a tensor\n",
    "pos_weight = torch.tensor([pos_weight_value], dtype=torch.float).to(device)\n",
    "\n",
    "# Now use it in your loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMNqbb0zkzvU"
   },
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRsm5jXM8GO"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].unsqueeze(1).to(device)  # shape: (batch, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4CqDHiRk3QF"
   },
   "source": [
    "### Evaluation Function\n",
    "Calculates:\n",
    "\n",
    "- Validation loss\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYYXX5ofNA8j"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_metrics(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            # Accuracy calculation\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # For AUC\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    val_loss = total_loss / len(dataloader)\n",
    "    val_acc = correct / total\n",
    "    val_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    return val_loss, val_acc, val_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tORWlUHWhYIR"
   },
   "source": [
    "## Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84n63esINCzs",
    "outputId": "7112bc55-9078-43ae-c388-e932aeeefff0"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, val_auc = evaluate_metrics(model, valid_loader, criterion, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvONgfjUH9AY",
    "outputId": "fca6591e-09bc-4673-a00d-fb876a3fe6f9"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_loss = train(model, valid_loader, optimizer, criterion, device)\n",
    "    #val_loss, val_acc, val_auc = evaluate_metrics(model, valid_loader, criterion, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    #print(f\"Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCblYQ0kgh3I"
   },
   "source": [
    "# **Section 4 - Evaluation Function**\n",
    "This section presents performance evaluation of the trained model using:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- ROC-AUC\n",
    "\n",
    "- Confusion Matrix\n",
    "\n",
    "- Multilingual and English-only test sets\n",
    "\n",
    "- Real-time prediction on personal input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXIQg23YDk7c"
   },
   "source": [
    "## Multilingual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoktLfCVQdZp",
    "outputId": "f5c02903-64ae-4e95-a010-b18ac2609f00"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import torch\n",
    "\n",
    "# Put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()  # convert logits to probs\n",
    "\n",
    "        all_probs.extend(probs)\n",
    "\n",
    "# Load true labels from test_labels DataFrame\n",
    "true = test_labels['toxic'].values\n",
    "\n",
    "# Convert predictions to NumPy array\n",
    "probs = np.array(all_probs).flatten()\n",
    "pred_labels = (probs > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(true, pred_labels)\n",
    "auc = roc_auc_score(true, probs)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuOxM_RAlzH_"
   },
   "source": [
    "### Confusion Matrix (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "58p1wIdGSrls",
    "outputId": "29444ff1-e818-45ad-a4b0-1471aa5985dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true, pred_labels)\n",
    "\n",
    "# Display it\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-toxic\", \"Toxic\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix Multilingual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXubYpBWDoRd"
   },
   "source": [
    "## English-only Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_ezOcjFQwYL",
    "outputId": "f4568fe0-f8e5-44bb-b0ee-75fb25c9da35"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_probs_en = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_en:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()  # convert logits to probabilities\n",
    "        all_probs_en.extend(probs)\n",
    "\n",
    "# Convert probabilities to binary labels\n",
    "pred_probs_en = np.array(all_probs_en).flatten()\n",
    "pred_labels_en = (pred_probs_en > 0.5).astype(int)\n",
    "\n",
    "# Load true labels from test_en DataFrame\n",
    "true_labels = test_en[\"toxic\"].values\n",
    "\n",
    "# Evaluate\n",
    "acc_en = accuracy_score(true_labels, pred_labels_en)\n",
    "auc_en = roc_auc_score(true_labels, pred_probs_en)\n",
    "\n",
    "print(f\"Accuracy: {acc_en:.4f}\")\n",
    "print(f\"AUC: {auc_en:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lSMQwTQmQZk"
   },
   "source": [
    "### Confusion Matrix (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "LDxKl32lRLSe",
    "outputId": "60d0b3cd-875d-4a3c-b49d-311f8a49bd02"
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels_en)\n",
    "\n",
    "# Display it\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-toxic\", \"Toxic\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix EN\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cllpHf9HfN5W"
   },
   "source": [
    "## Personal Input Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdvxIpqwfN5W"
   },
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer, max_len=192):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize input\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()[0][0]\n",
    "\n",
    "    # Classification\n",
    "    label = \"Toxic\" if probs > 0.5 else \"Non-toxic\"\n",
    "    return label, probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91d31c39"
   },
   "source": [
    "### Example Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygOw8KxffN5W",
    "outputId": "8b2a6a3c-07e0-458b-e97b-3c9743959670"
   },
   "outputs": [],
   "source": [
    "text = \"The design is terrible.\"\n",
    "label, probability = predict_text(text, model, tokenizer)\n",
    "print(f\"Label: {label} (Confidence: {probability:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9aGOpqtfN5W"
   },
   "source": [
    "# **Section 5 â€” Save and Load Model**\n",
    "This section outlines how to persist the trained model and tokenizer for later use, enabling:\n",
    "\n",
    "- Efficient reuse without retraining\n",
    "\n",
    "- Easy deployment or sharing\n",
    "\n",
    "- Quick inference and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hiw0O7lsh4z2"
   },
   "source": [
    "## Saving the Model & Tokenizer\n",
    "We save:\n",
    "\n",
    "- The model weights (`.pt` file)\n",
    "\n",
    "- The tokenizer configuration (`./tokenizer/` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEdV6sWknK0c",
    "outputId": "3ad1228a-862b-401f-cece-7731130dcf8f"
   },
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"toxic_model_v1.pt\")\n",
    "\n",
    "# Save tokenizer config and vocab\n",
    "tokenizer.save_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9crs-c4h78L"
   },
   "source": [
    "## Loading the Model & Tokenizer\n",
    "When reloading for evaluation, deployment, or further training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy-qdx9OfN5W",
    "outputId": "b65625fd-7193-421b-db36-dc81c52d4702"
   },
   "outputs": [],
   "source": [
    "# Re-instantiate model architecture\n",
    "model = ToxicClassifier()\n",
    "\n",
    "# Load saved weights\n",
    "model.load_state_dict(torch.load(\"toxic_model_v1.pt\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dg1msSdlfN5W"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec0a6bc2"
   },
   "source": [
    "# **Section 6 - Summary**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4QQlBJ7nfJ1"
   },
   "source": [
    "This project demonstrates the effectiveness of using DistilBERT for multilingual toxic comment classification, leveraging:\n",
    "\n",
    "- A lightweight yet powerful transformer architecture\n",
    "\n",
    "- Fine-tuning on labeled multilingual data\n",
    "\n",
    "- Evaluation across multilingual and English-only datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arTRtwronv4a"
   },
   "source": [
    "## Key Takeaways\n",
    "- **Strong Performance:** The model achieves high accuracy and ROC-AUC scores, especially when tested on both multilingual and English-specific samples.\n",
    "\n",
    "- **Generalizability:** Despite being trained on a subset, the classifier generalizes well across languages.\n",
    "\n",
    "- **Efficient Inference:** DistilBERT enables fast predictions without major compromises in performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlHAbcionhpb"
   },
   "source": [
    "## Future Work\n",
    "To further enhance results, potential next steps include:\n",
    "\n",
    "- Training with larger or full-scale datasets\n",
    "\n",
    "- Exploring deeper transformer models like XLM-R, BERTweet, or RoBERTa\n",
    "\n",
    "- Applying ensemble methods to combine strengths of multiple classifiers\n",
    "\n",
    "- Integrating contextual filtering or user behavior data for improved moderation accuracy\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
